{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":warning:**IMPORTANT NOTICE**:warning:\\\n",
    "*Since the initial parameterisation and gradient descent optimisation are stochastic processes, the training of a neural network is not fully reproducible.*\n",
    "\n",
    "*Therefore, it is not recommended to re-run this script as it will overwrite the original calibration of the neural network used in the work presented here.\n",
    "The purpose of this script is solely to document the training procedure and can be copied as a template to fit other new neural networks.*\n",
    "\n",
    "*To experiment with the models calibrated here, they can be loaded from the `saved_models` directory.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic assesment of different hyperparameters to optimise model performance\n",
    "\n",
    "Various hyperparameters are varied to asses their impact on the model performance in a semi-quantitative way.\\\n",
    "The hyperparameters that are varied are:\n",
    "- Number of hidden layers / neurons --> model capacity\n",
    "- Activation function\n",
    "- Effect of regularization\n",
    "\n",
    "The model is trained on the same dataset for each hyperparameter combination.\n",
    "\n",
    "### Model capacity\n",
    "\n",
    "These architectures are tested:\n",
    "- **small**: 2 hidden layers with 16 neurons each\n",
    "- **medium**: 2 hidden layers with 64 neurons each\n",
    "- **medium deep**: 4 hidden layers with 64 neurons each\n",
    "- **large**: 4 hidden layers with 128 neurons each\n",
    "- **large deep**: 6 hidden layers with 128 neurons each\n",
    "\n",
    "### Activation function\n",
    "\n",
    "These activation functions are tested:\n",
    "- relu\n",
    "- elu\n",
    "- leaky relu\n",
    "\n",
    "### Regularisation\n",
    "\n",
    "These regularisation methods are tested:\n",
    "- L2 regularisation\n",
    "- Dropout\n",
    "- Batch normalisation\n",
    "- Layer normalisation\n",
    "- Combined L2 regularisation and dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ThinkPad\\miniconda3\\envs\\masterproject\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Normalization, BatchNormalization, LayerNormalization, Dropout\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.optimizers import Adam, schedules\n",
    "from keras.metrics import MeanAbsoluteError, RootMeanSquaredError\n",
    "from keras.callbacks import CSVLogger, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ml_tb.normalisation import MinMaxScaler\n",
    "from ml_tb.metrics import RMSE_denormalised_P, RMSE_denormalised_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data, pre-procesing and train/test split\n",
    "\n",
    "For biotite composition only extract elements which are modelled to be present in biotite by ds55/62.\\\n",
    "Element-idx from hdf5 file:\n",
    "```python\n",
    "(0, 'O') (1, 'SI') (2, 'TI') (3, 'AL') (4, 'FE') (5, 'MG') (6, 'MN') (7, 'CA') (8, 'NA') (9, 'K') (10, 'H')\n",
    "```\n",
    "Only extract: Si, Ti, Al, Fe, Mg, Mn.\\\n",
    "K would be in modelled biotite, but is fixed at 1.0.\n",
    "\n",
    "Validation set is **10%** of the training set. Approx. 6000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'O') (1, 'SI') (2, 'TI') (3, 'AL') (4, 'FE') (5, 'MG') (6, 'MN') (7, 'CA') (8, 'NA') (9, 'K') (10, 'H')\n",
      "WARNING:tensorflow:From c:\\Users\\ThinkPad\\miniconda3\\envs\\masterproject\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "[[2.677286   0.11005508 1.524142   1.5183328  0.01044957 1.1597326 ]]\n",
      "[[0.09299828 0.04669439 0.16551827 0.31402156 0.0094105  0.27365792]]\n"
     ]
    }
   ],
   "source": [
    "# load hdf file\n",
    "file = Path(\"10022024_Biotite_ds62.hdf5\")\n",
    "with h5py.File(file, \"r\") as hdf_file:\n",
    "    PT = np.array(hdf_file[\"PT\"])\n",
    "    full_biotite_composition = np.array(hdf_file[\"mineral_composition\"])\n",
    "    element_idx = hdf_file[\"mineral_composition\"].attrs[\"element idx [apfu]\"]\n",
    "\n",
    "print(*enumerate(element_idx))\n",
    "\n",
    "biotite_composition = full_biotite_composition[:,[1, 2, 3, 4, 6, 5]]\n",
    "pt = PT\n",
    "\n",
    "biotite_composition_train, biotite_composition_val, pt_train, pt_val = train_test_split(biotite_composition, pt, test_size=0.10, shuffle=True)\n",
    "\n",
    "# normalise biotite composition & min-max scale PT\n",
    "normalisation_biotite_composition = Normalization(axis=-1)\n",
    "normalisation_biotite_composition.adapt(biotite_composition_train)\n",
    "\n",
    "print(normalisation_biotite_composition.mean.numpy())\n",
    "print(np.sqrt(normalisation_biotite_composition.variance.numpy()))\n",
    "\n",
    "scaling_pt = MinMaxScaler(min=[1500, 400], max=[10000, 900], axis=0)\n",
    "inv_scaling_pt = MinMaxScaler(min=[1500, 400], max=[10000, 900], axis=0, invert=True)\n",
    "pt_train_norm = scaling_pt(pt_train)\n",
    "pt_val_norm = scaling_pt(pt_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up global training parameters\n",
    "\n",
    "Define a function to calculate RMSE for pressure and temperature for unscaled values to have an interpretable metric.\n",
    "\n",
    "All models are trained for a maximum of 5000 epochs.\\\n",
    "Early stopping is used with a patience (no improvement of val loss) of 50 epochs.\\\n",
    "Inverse time learning rate decay is used for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_P(y_true, y_pred):\n",
    "    return RMSE_denormalised_P(y_true, y_pred, inv_scaling_pt)\n",
    "\n",
    "\n",
    "def RMSE_T(y_true, y_pred):\n",
    "    return RMSE_denormalised_T(y_true, y_pred, inv_scaling_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "STEPS_PER_EPOCH = len(biotite_composition_train) // BATCH_SIZE\n",
    "MAX_EPOCHS = 5000\n",
    "\n",
    "lr_schedule = schedules.InverseTimeDecay(0.001, decay_steps=STEPS_PER_EPOCH*1000, decay_rate=1, staircase=False)\n",
    "\n",
    "LOSS = MeanSquaredError()\n",
    "METRICS = [MeanAbsoluteError(), RootMeanSquaredError(), RMSE_P, RMSE_T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test 01:** Model capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALLBACKS_SMALL = [CSVLogger(\"baseline_small.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]\n",
    "CALLBACKS_MEDIUM = [CSVLogger(\"baseline_medium.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]\n",
    "CALLBACKS_MEDIUMDEEP = [CSVLogger(\"baseline_mediumdeep.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]\n",
    "CALLBACKS_LARGE = [CSVLogger(\"baseline_large.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]\n",
    "CALLBACKS_LARGEDEEP = [CSVLogger(\"baseline_largedeep.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                112       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 431 (1.69 KB)\n",
      "Trainable params: 418 (1.63 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "small_model = Sequential()\n",
    "small_model.add(normalisation_biotite_composition)\n",
    "small_model.add(Dense(16, activation=\"elu\"))\n",
    "small_model.add(Dense(16, activation=\"elu\"))\n",
    "small_model.add(Dense(2))\n",
    "\n",
    "small_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "small_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ThinkPad\\miniconda3\\envs\\masterproject\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ThinkPad\\miniconda3\\envs\\masterproject\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "INFO:tensorflow:Assets written to: saved_models\\small_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\small_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = small_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                          batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                          validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                          callbacks=CALLBACKS_SMALL, verbose=False)\n",
    "small_model.save(Path(\"saved_models\", \"small_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                448       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4751 (18.56 KB)\n",
      "Trainable params: 4738 (18.51 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "medium_model = Sequential()\n",
    "medium_model.add(normalisation_biotite_composition)\n",
    "medium_model.add(Dense(64, activation=\"elu\"))\n",
    "medium_model.add(Dense(64, activation=\"elu\"))\n",
    "medium_model.add(Dense(2))\n",
    "\n",
    "medium_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "medium_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\medium_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\medium_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = medium_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                           batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                           validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                           callbacks=CALLBACKS_MEDIUM, verbose=False)\n",
    "medium_model.save(Path(\"saved_models\", \"medium_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                448       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13071 (51.06 KB)\n",
      "Trainable params: 13058 (51.01 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "mediumdeep_model = Sequential()\n",
    "mediumdeep_model.add(normalisation_biotite_composition)\n",
    "mediumdeep_model.add(Dense(64, activation=\"elu\"))\n",
    "mediumdeep_model.add(Dense(64, activation=\"elu\"))\n",
    "mediumdeep_model.add(Dense(64, activation=\"elu\"))\n",
    "mediumdeep_model.add(Dense(64, activation=\"elu\"))\n",
    "mediumdeep_model.add(Dense(2))\n",
    "\n",
    "mediumdeep_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "mediumdeep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\mediumdeep_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\mediumdeep_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = mediumdeep_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                               batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                               validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                               callbacks=CALLBACKS_MEDIUMDEEP, verbose=False)\n",
    "mediumdeep_model.save(Path(\"saved_models\", \"mediumdeep_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               896       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50703 (198.06 KB)\n",
      "Trainable params: 50690 (198.01 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "large_model = Sequential()\n",
    "large_model.add(normalisation_biotite_composition)\n",
    "large_model.add(Dense(128, activation=\"elu\"))\n",
    "large_model.add(Dense(128, activation=\"elu\"))\n",
    "large_model.add(Dense(128, activation=\"elu\"))\n",
    "large_model.add(Dense(128, activation=\"elu\"))\n",
    "large_model.add(Dense(2))\n",
    "\n",
    "large_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "large_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\large_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\large_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = large_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                          batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                          validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                          callbacks=CALLBACKS_LARGE, verbose=False)\n",
    "large_model.save(Path(\"saved_models\", \"large_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               896       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83727 (327.06 KB)\n",
      "Trainable params: 83714 (327.01 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "largedeep_model = Sequential()\n",
    "largedeep_model.add(normalisation_biotite_composition)\n",
    "largedeep_model.add(Dense(128, activation=\"elu\"))\n",
    "largedeep_model.add(Dense(128, activation=\"elu\"))\n",
    "largedeep_model.add(Dense(128, activation=\"elu\"))\n",
    "largedeep_model.add(Dense(128, activation=\"elu\"))\n",
    "largedeep_model.add(Dense(128, activation=\"elu\"))\n",
    "largedeep_model.add(Dense(128, activation=\"elu\"))\n",
    "largedeep_model.add(Dense(2))\n",
    "\n",
    "largedeep_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "largedeep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\largedeep_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\largedeep_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = largedeep_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                              batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                              validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                              callbacks=CALLBACKS_LARGEDEEP, verbose=False)\n",
    "largedeep_model.save(Path(\"saved_models\", \"largedeep_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test 02:** Activation function\n",
    "\n",
    "All tests on the architecture determined to be optimal in test 01. --> medium_deep. 4 hidden layers with 64 neurons each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALLBACKS_elu = [CSVLogger(\"baseline_elu.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]\n",
    "CALLBACKS_relu = [CSVLogger(\"baseline_relu.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]\n",
    "CALLBACKS_leaky_relu = [CSVLogger(\"baseline_leaky_relu.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 64)                448       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13071 (51.06 KB)\n",
      "Trainable params: 13058 (51.01 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "elu_model = Sequential()\n",
    "elu_model.add(normalisation_biotite_composition)\n",
    "elu_model.add(Dense(64, activation=\"elu\"))\n",
    "elu_model.add(Dense(64, activation=\"elu\"))\n",
    "elu_model.add(Dense(64, activation=\"elu\"))\n",
    "elu_model.add(Dense(64, activation=\"elu\"))\n",
    "elu_model.add(Dense(2))\n",
    "\n",
    "elu_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "elu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\elu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\elu_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = elu_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                        batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                        validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                        callbacks=CALLBACKS_elu, verbose=False)\n",
    "elu_model.save(Path(\"saved_models\", \"elu_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                448       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 64)                4160      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_32 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13071 (51.06 KB)\n",
      "Trainable params: 13058 (51.01 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "relu_model = Sequential()\n",
    "relu_model.add(normalisation_biotite_composition)\n",
    "relu_model.add(Dense(64, activation=\"relu\"))\n",
    "relu_model.add(Dense(64, activation=\"relu\"))\n",
    "relu_model.add(Dense(64, activation=\"relu\"))\n",
    "relu_model.add(Dense(64, activation=\"relu\"))\n",
    "relu_model.add(Dense(2))\n",
    "\n",
    "relu_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "relu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\relu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\relu_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = relu_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                         batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                         validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                         callbacks=CALLBACKS_relu, verbose=False)\n",
    "relu_model.save(Path(\"saved_models\", \"relu_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 64)                448       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13071 (51.06 KB)\n",
      "Trainable params: 13058 (51.01 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "leaky_relu_model = Sequential()\n",
    "leaky_relu_model.add(normalisation_biotite_composition)\n",
    "leaky_relu_model.add(Dense(64, activation=\"leaky_relu\"))\n",
    "leaky_relu_model.add(Dense(64, activation=\"leaky_relu\"))\n",
    "leaky_relu_model.add(Dense(64, activation=\"leaky_relu\"))\n",
    "leaky_relu_model.add(Dense(64, activation=\"leaky_relu\"))\n",
    "leaky_relu_model.add(Dense(2))\n",
    "\n",
    "leaky_relu_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "leaky_relu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\leakyrelu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\leakyrelu_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = leaky_relu_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                               batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                               validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                               callbacks=CALLBACKS_leaky_relu, verbose=False)\n",
    "leaky_relu_model.save(Path(\"saved_models\", \"leakyrelu_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test 03:** Regularisation\n",
    "\n",
    "Test if regularisation can improve performance if applied to models with the best training set performance determined in tests 01 and 02.\\\n",
    "Model architecture: large_deep. 6 hidden layers with 128 neurons each.\\\n",
    "Activation function: relu.\n",
    "\n",
    "\n",
    "The idea behind this test is to see if regularisation can prevent overfitting and improve the performance on the validation set beyond what is achieved by smaller models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALLBACKS_noReg = [CSVLogger(\"baseline_noReg.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]\n",
    "CALLBACKS_L2 = [CSVLogger(\"baseline_L2.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]\n",
    "CALLBACKS_dropout = [CSVLogger(\"baseline_dropout.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]\n",
    "CALLBACKS_BatchNorm = [CSVLogger(\"baseline_BatchNorm.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]\n",
    "CALLBACKS_LayerNorm = [CSVLogger(\"baseline_LayerNorm.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]\n",
    "CALLBACKS_L2_dropout = [CSVLogger(\"baseline_L2_dropout.log\", append=False), EarlyStopping(monitor=\"loss\", patience=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 128)               896       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83727 (327.06 KB)\n",
      "Trainable params: 83714 (327.01 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "noReg_model = Sequential()\n",
    "noReg_model.add(normalisation_biotite_composition)\n",
    "noReg_model.add(Dense(128, activation=\"relu\"))\n",
    "noReg_model.add(Dense(128, activation=\"relu\"))\n",
    "noReg_model.add(Dense(128, activation=\"relu\"))\n",
    "noReg_model.add(Dense(128, activation=\"relu\"))\n",
    "noReg_model.add(Dense(128, activation=\"relu\"))\n",
    "noReg_model.add(Dense(128, activation=\"relu\"))\n",
    "noReg_model.add(Dense(2))\n",
    "\n",
    "noReg_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "noReg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\noReg_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\noReg_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = noReg_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                          batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                          validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                          callbacks=CALLBACKS_noReg, verbose=False)\n",
    "noReg_model.save(Path(\"saved_models\", \"noReg_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 128)               896       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83727 (327.06 KB)\n",
      "Trainable params: 83714 (327.01 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "L2_model = Sequential()\n",
    "L2_model.add(normalisation_biotite_composition)\n",
    "L2_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "L2_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "L2_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "L2_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "L2_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "L2_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "L2_model.add(Dense(2))\n",
    "\n",
    "L2_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "L2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\L2_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\L2_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = L2_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                         batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                         validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                         callbacks=CALLBACKS_L2, verbose=False)\n",
    "L2_model.save(Path(\"saved_models\", \"L2_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 128)               896       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83727 (327.06 KB)\n",
      "Trainable params: 83714 (327.01 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "dropout_model = Sequential()\n",
    "dropout_model.add(normalisation_biotite_composition)\n",
    "dropout_model.add(Dense(128, activation=\"relu\"))\n",
    "dropout_model.add(Dropout(0.2))\n",
    "dropout_model.add(Dense(128, activation=\"relu\"))\n",
    "dropout_model.add(Dropout(0.2))\n",
    "dropout_model.add(Dense(128, activation=\"relu\"))\n",
    "dropout_model.add(Dropout(0.2))\n",
    "dropout_model.add(Dense(128, activation=\"relu\"))\n",
    "dropout_model.add(Dropout(0.2))\n",
    "dropout_model.add(Dense(128, activation=\"relu\"))\n",
    "dropout_model.add(Dropout(0.2))\n",
    "dropout_model.add(Dense(128, activation=\"relu\"))\n",
    "dropout_model.add(Dropout(0.2))\n",
    "dropout_model.add(Dense(2))\n",
    "\n",
    "dropout_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "dropout_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\dropout_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\dropout_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = dropout_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                         batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                         validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                         callbacks=CALLBACKS_dropout, verbose=False)\n",
    "dropout_model.save(Path(\"saved_models\", \"dropout_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 128)               896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 128)               512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86799 (339.06 KB)\n",
      "Trainable params: 85250 (333.01 KB)\n",
      "Non-trainable params: 1549 (6.05 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "BatchNorm_model = Sequential()\n",
    "BatchNorm_model.add(normalisation_biotite_composition)\n",
    "BatchNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "BatchNorm_model.add(BatchNormalization())\n",
    "BatchNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "BatchNorm_model.add(BatchNormalization())\n",
    "BatchNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "BatchNorm_model.add(BatchNormalization())\n",
    "BatchNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "BatchNorm_model.add(BatchNormalization())\n",
    "BatchNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "BatchNorm_model.add(BatchNormalization())\n",
    "BatchNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "BatchNorm_model.add(BatchNormalization())\n",
    "BatchNorm_model.add(Dense(2))\n",
    "\n",
    "BatchNorm_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "BatchNorm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\BatchNorm_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\BatchNorm_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = BatchNorm_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                              batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                              validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                              callbacks=CALLBACKS_BatchNorm, verbose=False)\n",
    "BatchNorm_model.save(Path(\"saved_models\", \"BatchNorm_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ThinkPad\\miniconda3\\envs\\masterproject\\Lib\\site-packages\\keras\\src\\layers\\normalization\\layer_normalization.py:328: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ThinkPad\\miniconda3\\envs\\masterproject\\Lib\\site-packages\\keras\\src\\layers\\normalization\\layer_normalization.py:328: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 128)               896       \n",
      "                                                                 \n",
      " layer_normalization (Layer  (None, 128)               256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " layer_normalization_1 (Lay  (None, 128)               256       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " layer_normalization_2 (Lay  (None, 128)               256       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " layer_normalization_3 (Lay  (None, 128)               256       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " layer_normalization_4 (Lay  (None, 128)               256       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " layer_normalization_5 (Lay  (None, 128)               256       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85263 (333.06 KB)\n",
      "Trainable params: 85250 (333.01 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "LayerNorm_model = Sequential()\n",
    "LayerNorm_model.add(normalisation_biotite_composition)\n",
    "LayerNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "LayerNorm_model.add(LayerNormalization())\n",
    "LayerNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "LayerNorm_model.add(LayerNormalization())\n",
    "LayerNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "LayerNorm_model.add(LayerNormalization())\n",
    "LayerNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "LayerNorm_model.add(LayerNormalization())\n",
    "LayerNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "LayerNorm_model.add(LayerNormalization())\n",
    "LayerNorm_model.add(Dense(128, activation=\"relu\"))\n",
    "LayerNorm_model.add(LayerNormalization())\n",
    "LayerNorm_model.add(Dense(2))\n",
    "\n",
    "LayerNorm_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "LayerNorm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\LayerNorm_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\LayerNorm_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = LayerNorm_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                              batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                              validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                              callbacks=CALLBACKS_LayerNorm, verbose=False)\n",
    "LayerNorm_model.save(Path(\"saved_models\", \"LayerNorm_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 6)                 13        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 128)               896       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83727 (327.06 KB)\n",
      "Trainable params: 83714 (327.01 KB)\n",
      "Non-trainable params: 13 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OPT = Adam(lr_schedule)\n",
    "\n",
    "l2_dropout_model = Sequential()\n",
    "l2_dropout_model.add(normalisation_biotite_composition)\n",
    "l2_dropout_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "l2_dropout_model.add(Dropout(0.2))\n",
    "l2_dropout_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "l2_dropout_model.add(Dropout(0.2))\n",
    "l2_dropout_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "l2_dropout_model.add(Dropout(0.2))\n",
    "l2_dropout_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "l2_dropout_model.add(Dropout(0.2))\n",
    "l2_dropout_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "l2_dropout_model.add(Dropout(0.2))\n",
    "l2_dropout_model.add(Dense(128, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "l2_dropout_model.add(Dropout(0.2))\n",
    "l2_dropout_model.add(Dense(2))\n",
    "\n",
    "l2_dropout_model.compile(optimizer=OPT, loss=LOSS, metrics=METRICS)\n",
    "l2_dropout_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\L2_dropout_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\L2_dropout_model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = l2_dropout_model.fit(biotite_composition_train, pt_train_norm,\n",
    "                              batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                              validation_data=[biotite_composition_val, pt_val_norm],\n",
    "                              callbacks=CALLBACKS_L2_dropout, verbose=False)\n",
    "l2_dropout_model.save(Path(\"saved_models\", \"L2_dropout_model\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
