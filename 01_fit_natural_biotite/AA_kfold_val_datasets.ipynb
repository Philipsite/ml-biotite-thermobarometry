{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":warning:**IMPORTANT NOTICE**:warning:\\\n",
    "*Since the k-fold splitting is a stochastic processes, this notebook is not fully reproducible.*\n",
    "\n",
    "*Therefore, it is not recommended to re-run this script as it will overwrite the original validation data used in the work presented here.\n",
    "The purpose of this script is solely a documentation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate K-fold cross-validation splits\n",
    "\n",
    "This notebook generates 5 validation sets which can then be used to evaluate perfromance of different models in the model selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThinkPad\\AppData\\Local\\Temp\\ipykernel_6428\\1058610788.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load excel file\n",
    "data = pd.read_excel(Path(\"Metapelite-Database_Bt_CLEAN_2024-02-03.xlsx\"))\n",
    "\n",
    "biotite_composition = np.zeros(shape=(len(data), 6))\n",
    "biotite_composition[:, 0] = data[\"Bt-Si\"]\n",
    "biotite_composition[:, 1] = data[\"Bt-Ti\"]\n",
    "biotite_composition[:, 2] = data[\"Bt-Al\"]\n",
    "biotite_composition[:, 3] = data[\"Bt-FeTot\"]\n",
    "biotite_composition[:, 4] = data[\"Bt-Mn\"]\n",
    "biotite_composition[:, 5] = data[\"Bt-Mg\"]\n",
    "\n",
    "# also save XMg\n",
    "biotite_XMg = np.array([data[\"Bt-XMg\"]]).T\n",
    "\n",
    "# extract one-hot encoded minerals in the following order: Chl, Grt, Crd, And, St, Ky, Sil, Kfs\n",
    "index_minerals = np.zeros(shape=(len(data), 8))\n",
    "index_minerals[:, 0] = data[\"Chl\"]\n",
    "index_minerals[:, 1] = data[\"Grt\"]\n",
    "index_minerals[:, 2] = data[\"Crd\"]\n",
    "index_minerals[:, 3] = data[\"And\"]\n",
    "index_minerals[:, 4] = data[\"St\"]\n",
    "index_minerals[:, 5] = data[\"Ky\"]\n",
    "index_minerals[:, 6] = data[\"Sil\"]\n",
    "index_minerals[:, 7] = data[\"Kfs\"]\n",
    "\n",
    "# Some minerals (Chl, Grt, St) have NaN values. Replace them with 0. Most likely samples with regional or metastable phases?!\n",
    "index_minerals = np.nan_to_num(index_minerals, nan=0)\n",
    "\n",
    "# combine biotite composition and one-hot encoded minerals\n",
    "biotite_composition_idxmin = np.concatenate((biotite_composition, biotite_XMg, index_minerals), axis=1)\n",
    "\n",
    "pt = np.zeros(shape=(len(data), 2))\n",
    "pt[:, 0] = data[\"Pressure estimate random uniform\"] * 1000 # convert to bar\n",
    "pt[:, 1] = data[\"Temperature random ordered after Ti-in-Bt\"]\n",
    "\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "for i, idx in enumerate(ss.split(biotite_composition_idxmin, pt)):\n",
    "    train_index = idx[0]\n",
    "    test_index = idx[1]\n",
    "\n",
    "    training_x = biotite_composition_idxmin[train_index]\n",
    "    training_y = pt[train_index]\n",
    "\n",
    "    test_x = biotite_composition_idxmin[test_index]\n",
    "    test_y = pt[test_index]\n",
    "\n",
    "    # save training and test data as csv files\n",
    "    train_file = Path(\"kfold_datasets\",f\"train_data_{i}.csv\")\n",
    "    test_file = Path(\"kfold_datasets\",f\"test_data_{i}.csv\")\n",
    "\n",
    "    np.savetxt(train_file, np.concatenate((training_x, training_y), axis=1), delimiter=\",\")\n",
    "    np.savetxt(test_file, np.concatenate((test_x, test_y), axis=1), delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
